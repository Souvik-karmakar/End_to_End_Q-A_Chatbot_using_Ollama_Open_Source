# ğŸ¦™ Ollama Q&A Chatbot

An **interactive Q&A chatbot** built using **Streamlit**, **LangChain**, and **Ollama open-source LLMs**.  
This app allows you to chat with models like **phi3** or **gemma2** locally, with a **clean chat-style interface**, session-based conversation memory, and adjustable response settings.  

The application is **deployed on Streamlit** for easy access and sharing.

---

## ğŸš€ Live Demo

ğŸ‘‰ **Deployed on Streamlit:**  
*https://endtoendq-achatbotusingollamaopensource-5rhwj6757soxj8inkgkbr4.streamlit.app/*

---

## âœ¨ Features

- ğŸ’¬ ChatGPT-style interface with messages grouped by user/assistant
- ğŸ¦™ Supports open-source Ollama models (**phi3**, **gemma2**)
- ğŸ›ï¸ Adjustable model settings:
  - Temperature (creativity)
  - Max Tokens (response length)
- ğŸ§¹ Clear chat history with a single click
- âš¡ Fast, lightweight, and easy to use
- ğŸ’¾ Session-based chat memory for continuous conversation

---

## ğŸ› ï¸ Tech Stack

- **Frontend:** Streamlit  
- **LLM Framework:** LangChain  
- **Models:** Ollama open-source models (phi3, gemma2)  
- **Language:** Python  
- **Deployment:** Streamlit Cloud  

---
## ğŸ“ Project Structure
- â”œâ”€â”€ app.py # Main Streamlit application
- â”œâ”€â”€ requirements.txt # Python dependencies
- â”œâ”€â”€ README.md # Project documentation
- â”œâ”€â”€ runtime.tx
---

## âš™ï¸ Installation & Setup (Local)

### 1. Clone the repository
```bash
git clone https://github.com/your-username/ollama-qna-chatbot.git
cd ollama-qna-chatbot


